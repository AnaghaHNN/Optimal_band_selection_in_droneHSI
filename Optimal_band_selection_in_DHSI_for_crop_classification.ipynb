{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pylab as py\n",
    "import rasterio\n",
    "import cv2\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b6ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_input():\n",
    "    print(\"\\n Input the source image file: \\n\")\n",
    "    tk.Tk().withdraw()\n",
    "    Source_image = filedialog.askopenfilename()\n",
    "    print(Source_image)\n",
    "    img=rasterio.open(Source_image)\n",
    "    img=img.read()\n",
    "    imgarr=np.moveaxis(img,0,-1)\n",
    "    Xs=imgarr#[216:716,235:735,:-1]\n",
    "    Xs=Xs.reshape(Xs.shape[0]*Xs.shape[1],Xs.shape[2])\n",
    "    Xs_norm = (Xs-np.min(Xs))/(np.max(Xs)- np.min(Xs))\n",
    "\n",
    "    print(\"\\n Input the ground_truth_file: \\n\")\n",
    "    tk.Tk().withdraw()\n",
    "    GT_file = filedialog.askopenfilename()\n",
    "    print(GT_file)\n",
    "    y=rasterio.open(GT_file)\n",
    "    y=y.read()\n",
    "    y=np.moveaxis(y,0,-1)\n",
    "    yt=y.reshape(y.shape[0]*y.shape[1])\n",
    "        \n",
    "        #label_encoding\n",
    "    from sklearn import preprocessing\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    labels= label_encoder.fit_transform(yt)\n",
    "       \n",
    "    return Xs_norm, labels,imgarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199921d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s, labels, image_s=data_input()\n",
    "rows=image_s.shape[0]\n",
    "cols=image_s.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bands=X_s.shape[1]\n",
    "num_pixels=X_s.shape[0]\n",
    "num_classes=len(np.unique(labels)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e390a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def sample_data(data, labels):\n",
    "    df  = pd.DataFrame(data[labels!=0])\n",
    "    df['label'] = labels[labels!=0]  # Add labels as a new column\n",
    "\n",
    "    # Group by the 'label' column and take the first 1000 samples from each class\n",
    "    sampled_df  = df.groupby('label').head(6000)\n",
    "\n",
    "    # data and labels as separate arrays:\n",
    "    sampled_data  = sampled_df.drop('label', axis=1).to_numpy()\n",
    "    sampled_labels  = sampled_df['label'].to_numpy()\n",
    "    return sampled_data, sampled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610bd2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valuation_fn(data, labels):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,labels,random_state=42,stratify=labels)\n",
    "    count={}\n",
    "    for i in range (1,len(np.unique(y_test))+1):\n",
    "        counts=len(np.where(y_test==i)[0])\n",
    "        count[i]=counts\n",
    "    print(count)\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "    model2=RidgeClassifier()\n",
    "    model6=SVC(kernel='rbf',probability=True)\n",
    "    model10=RandomForestClassifier(n_estimators=100)\n",
    "    ensemble = VotingClassifier(estimators=[('SVC', model6),('RF', model10),('Ridge', model2)], voting='hard')\n",
    "    fit_model=ensemble.fit(X_train, y_train) \n",
    "    y_pred=fit_model.predict(X_test) \n",
    "\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test ,y_pred)\n",
    "    cohen_kappa_score_vals = cohen_kappa_score(y_test ,y_pred)\n",
    "    balanced_accuracy_score_vals = balanced_accuracy_score(y_test ,y_pred)\n",
    "    accuracy_score_vals = accuracy_score(y_test ,y_pred)\n",
    "    classification_report_vals = classification_report(y_test ,y_pred)\n",
    "    f1_score_vals = f1_score(y_test ,y_pred, average='weighted')\n",
    "    precision_score_vals = precision_score(y_test ,y_pred,average='weighted')\n",
    "    #precision = precision_score(y_test ,y_pred, labels=[1, 2, 3], average='micro')\n",
    "    recall_score_vals = recall_score(y_test ,y_pred, average='weighted')\n",
    "\n",
    "\n",
    "    print(\"confusion_matrix = \"'\\n', conf_matrix,'\\n', \"cohen_kappa_score = \", cohen_kappa_score_vals,'\\n',\"balanced_accuracy_score = \",balanced_accuracy_score_vals,'\\n',\"accuracy_score = \",accuracy_score_vals, '\\n', \"classification_report =\"'\\n',classification_report_vals,\"f1_score = \",f1_score_vals,'\\n', \"precision_score = \", precision_score_vals,'\\n', \"recall_score = \",recall_score_vals)\n",
    "    return balanced_accuracy_score_vals, conf_matrix, classification_report, fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995fce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data_full, sampled_labels_full = sample_data(X_s, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_full, conf_matrix_full, classification_report_full, fit_model_full=valuation_fn(sampled_data_full, sampled_labels_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ddd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Input the wavelength file: \\n\")\n",
    "tk.Tk().withdraw()\n",
    "wavelength_file = filedialog.askopenfilename()\n",
    "print(wavelength_file)\n",
    "wavelengths=np.loadtxt(wavelength_file)\n",
    "wv= {}\n",
    "for i in range(0,X_s.shape[1]):\n",
    "    wv[i] = wavelengths[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "    'font.size': 20  \n",
    "})\n",
    "    # Compute the distribution for each band\n",
    "for band in range(image_s.shape[2]-1):\n",
    "    data = image_s[:, :, band].flatten()\n",
    "    plt.hist(data, bins=50, alpha=0.6, label=f'Band {band+1}')\n",
    "    \n",
    "plt.xlabel('Pixel Value')\n",
    "plt.ylabel('Frequency')\n",
    "#plt.title('Histogram of Hyperspectral Bands')\n",
    "tk.Tk().withdraw()\n",
    "\n",
    "print(\"Select a location to save the figure:\")\n",
    "save_file_path = filedialog.asksaveasfilename()\n",
    "print(save_file_path)\n",
    "plt.savefig(save_file_path, dpi = 600,bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27155ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_s=image_s.reshape(image_s.shape[0]*image_s.shape[1], image_s.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import weibull_min\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_class_A = images_s[labels==1][:,:-1] \n",
    "data_class_B = images_s[labels==2][:,:-1]\n",
    "data_class_C = images_s[labels==3][:,:-1]\n",
    "\n",
    "\n",
    "# Function to fit Weibull distribution and return shape and scale parameters\n",
    "def fit_weibull(data):\n",
    "    shape, loc, scale = weibull_min.fit(data, floc=0)\n",
    "    return shape, scale\n",
    "\n",
    "# Calculate Weibull parameters for each class and band\n",
    "weibull_params_A = [fit_weibull(data_class_A[:, i]) for i in range(data_class_A.shape[1])]\n",
    "weibull_params_B = [fit_weibull(data_class_B[:, i]) for i in range(data_class_B.shape[1])]\n",
    "weibull_params_C = [fit_weibull(data_class_C[:, i]) for i in range(data_class_C.shape[1])]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Weibull PDF\n",
    "def weibull_pdf(x, shape, scale):\n",
    "    return (shape / scale) * (x / scale)**(shape - 1) * np.exp(-(x / scale)**shape)\n",
    "\n",
    "# Bhattacharyya coefficient for two Weibull distributions\n",
    "def bhattacharyya_coefficient(shape1, scale1, shape2, scale2):\n",
    "    integrand = lambda x: np.sqrt(weibull_pdf(x, shape1, scale1) * weibull_pdf(x, shape2, scale2))\n",
    "    bc, _ = quad(integrand, 0, np.inf)\n",
    "    return bc\n",
    "\n",
    "# Bhattacharyya distance for two distributions\n",
    "def bhattacharyya_distance(shape1, scale1, shape2, scale2):\n",
    "    bc = bhattacharyya_coefficient(shape1, scale1, shape2, scale2)\n",
    "    return -np.log(bc)\n",
    "\n",
    "# Compute the separability for each band between Class A and B\n",
    "separability_AB = [bhattacharyya_distance(weibull_params_A[i][0], weibull_params_A[i][1],\n",
    "                                        weibull_params_B[i][0], weibull_params_B[i][1])\n",
    "                 for i in range(data_class_A.shape[1])]\n",
    "\n",
    "# Compute the separability for each band between Class B and C\n",
    "separability_BC = [bhattacharyya_distance(weibull_params_B[i][0], weibull_params_B[i][1],\n",
    "                                        weibull_params_C[i][0], weibull_params_C[i][1])\n",
    "                 for i in range(data_class_B.shape[1])]\n",
    "\n",
    "separability_AC = [bhattacharyya_distance(weibull_params_A[i][0], weibull_params_A[i][1],\n",
    "                                        weibull_params_C[i][0], weibull_params_C[i][1])\n",
    "                 for i in range(data_class_A.shape[1])]\n",
    "\n",
    "\n",
    "selected_bands_AB = np.argsort(separability_AB)[-(int(images_s.shape[1]/4)):] \n",
    "selected_bands_BC = np.argsort(separability_BC)[-(int(images_s.shape[1]/4)):] \n",
    "selected_bands_AC = np.argsort(separability_AC)[-(int(images_s.shape[1]/4)):] \n",
    "\n",
    "def combined_bands(a,b,c): \n",
    "    combined = np.concatenate((a, b, c))\n",
    "    unique_combined = np.unique(combined)\n",
    "    return unique_combined \n",
    "\n",
    "selected_bands = combined_bands(selected_bands_AB, selected_bands_BC, selected_bands_AC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680c739",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_colors = [ 'navy', '#CB0000', '#E4EA8C']\n",
    "\n",
    "legend_label=['S$_{AB}$', 'S$_{BC}$','S$_{AC}$']\n",
    "# Plotting the spectral signatures\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.plot(wavelengths[:-1], separability_AB, marker='o', linewidth=3, color= user_colors[0], label=legend_label[0])\n",
    "plt.plot(wavelengths[:-1], separability_BC, marker='o',linewidth=3,color= user_colors[1],label=legend_label[1])\n",
    "plt.plot(wavelengths[:-1], separability_AC, marker='o',linewidth=3,color= user_colors[2],label=legend_label[2])\n",
    "\n",
    "# Add common x-axis label and adjust layout\n",
    "plt.xlabel(\"Wavelengths (nm)\")\n",
    "plt.ylabel(\"Separability\")\n",
    "plt.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(1,1))\n",
    "tk.Tk().withdraw()\n",
    "\n",
    "print(\"Select a location to save the figure:\")\n",
    "save_file_path = filedialog.asksaveasfilename()\n",
    "print(save_file_path)\n",
    "plt.savefig(save_file_path, dpi = 600,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230211ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "\n",
    "for i in range(len(weibull_params_C)-1):\n",
    "    ax1.plot(i, weibull_params_C[i][0], color='#C5001A', marker = 'o', alpha=0.6)\n",
    "\n",
    "# Set the labels and title for the first y-axis\n",
    "ax1.set_xlabel('Band_index')\n",
    "ax1.set_ylabel(r'Scale ($\\alpha$)',color='#C5001A')\n",
    "ax1.tick_params(axis='y')#, labelcolor='g')\n",
    "\n",
    "# Create the second y-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the second set of Weibull parameters on the second y-axis\n",
    "for i in range(len(weibull_params_C)-1):\n",
    "    ax2.plot(i, weibull_params_C[i][1], color ='#002C54', marker = '*', alpha=0.6)\n",
    "\n",
    "# Set the labels for the second y-axis\n",
    "ax2.set_ylabel(r'Shape ($\\gamma$)',color='#002C54')\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Adding legend and title\n",
    "fig.suptitle('Weibull Distribution for Class C')\n",
    "tk.Tk().withdraw()\n",
    "\n",
    "print(\"Select a location to save the figure:\")\n",
    "save_file_path = filedialog.asksaveasfilename()\n",
    "print(save_file_path)\n",
    "plt.savefig(save_file_path, dpi=600,bbox_inches='tight', pad_inches=0)\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d201a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "classes = {}\n",
    "class_means = {}\n",
    "lb = np.unique(labels)[1:] \n",
    "\n",
    "user_colors = [ '#375E97', '#FB6542', '#FFBB00'] \n",
    "\n",
    "for i in lb:\n",
    "    # Select data for each class\n",
    "    class_data = X_s[labels == i]    \n",
    "    class_sig = np.mean(class_data[:6000, :-1],axis=0)\n",
    "    class_means[f'class{i}_mean'] = class_sig  \n",
    "\n",
    "# Create a DataFrame from the class means dictionary\n",
    "class_means_df = pd.DataFrame.from_dict(class_means, orient='index')\n",
    "legend_label=['Cabbage', 'Eggplant','Tomato']\n",
    "label_linestyle=[\"-\", \"--\",\":\"]\n",
    "# Plotting the spectral signatures\n",
    "plt.figure(figsize=(6,5))\n",
    "for i in range(len(lb)):\n",
    "    plt.plot(wavelengths[:-1], class_means_df.iloc[i], color=user_colors[i % len(user_colors)], label=legend_label[i % len(legend_label)], linestyle=label_linestyle[i % len(label_linestyle)], linewidth=3)\n",
    "\n",
    "# Add legends and labels\n",
    "plt.legend()\n",
    "plt.xlabel('Wavelength (nm) \\n')\n",
    "plt.ylabel('Normalised Reflectance')\n",
    "#plt.title('Spectral_Signature of Crops')\n",
    "tk.Tk().withdraw()\n",
    "\n",
    "print(\"Select a location to save the figure:\")\n",
    "save_file_path = filedialog.asksaveasfilename()\n",
    "print(save_file_path)\n",
    "plt.savefig(save_file_path, dpi=600, bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(selected_bands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af9b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_values = {k: wv[k] for k in selected_bands if k in wv}\n",
    "X_sreduced=X_s[:,selected_bands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a089a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_Weibull1=[]\n",
    "array_Weibull2=[]\n",
    "array_Weibull3=[]\n",
    "array_Weibull4=[]\n",
    "array_Weibull5=[]\n",
    "array_Weibull6=[]\n",
    "\n",
    "for i in range(0,len(selected_values)):\n",
    "    if 450<=(list(selected_values.values())[i])<550:\n",
    "        array_Weibull1.append(list(selected_values.values())[i])\n",
    "    if 550<=(list(selected_values.values())[i])<650:\n",
    "        array_Weibull2.append(list(selected_values.values())[i])\n",
    "    if 650<=(list(selected_values.values())[i])<750:\n",
    "        array_Weibull3.append(list(selected_values.values())[i])\n",
    "    if 750<=(list(selected_values.values())[i])<850:\n",
    "        array_Weibull4.append(list(selected_values.values())[i])\n",
    "    if 850<=(list(selected_values.values())[i])<950:\n",
    "        array_Weibull5.append(list(selected_values.values())[i])\n",
    "    if 950<=(list(selected_values.values())[i])<1050:\n",
    "        array_Weibull6.append(list(selected_values.values())[i])\n",
    "        \n",
    "print(\"\\n Weibull wavelengths:\\n\")       \n",
    "print(\"Wavelengths in range 450-550 nm:\", array_Weibull1)\n",
    "print(\"Wavelengths in range 550-650 nm:\", array_Weibull2)\n",
    "print(\"Wavelengths in range 650-750 nm:\", array_Weibull3)\n",
    "print(\"Wavelengths in range 750-850 nm:\", array_Weibull4)\n",
    "print(\"Wavelengths in range 850-950 nm:\", array_Weibull5)\n",
    "print(\"Wavelengths in range 950-1050 nm:\", array_Weibull6)\n",
    "\n",
    "print(\"Wavelengths in range 450-550 nm:\",len(array_Weibull1))\n",
    "print(\"Wavelengths in range 550-650 nm:\", len(array_Weibull2))\n",
    "print(\"Wavelengths in range 650-750 nm:\", len(array_Weibull3))\n",
    "print(\"Wavelengths in range 750-850 nm:\",len (array_Weibull4))\n",
    "print(\"Wavelengths in range 850-950 nm:\",len (array_Weibull5))\n",
    "print(\"Wavelengths in range 950-1050 nm:\",len (array_Weibull6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab1f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count={}\n",
    "for i in range (1,len(np.unique(labels))):\n",
    "    counts=len(np.where(labels==i)[0])\n",
    "    count[i]=counts\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c5e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data_reduced, sampled_labels_reduced = sample_data(X_sreduced, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_reduced, conf_matrix_reduced, classification_report_reduced, fit_model_reduced=valuation_fn(sampled_data_reduced,sampled_labels_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(individual,data, labels): \n",
    "    bands=np.where(individual!=0) \n",
    "    data=data[:,bands[0]]\n",
    "    \n",
    "    #sum of non diagonal elements of correlation matrix\n",
    "    corrm = np.corrcoef(data, rowvar=False)\n",
    "    if corrm.ndim >= 2:\n",
    "        corrsum = np.sum(corrm) - np.trace(corrm)\n",
    "    else:\n",
    "        corrsum = np.sum(corrm)\n",
    "   \n",
    "    X_temp =pd.DataFrame(data) \n",
    "    X_temp['labels']=labels \n",
    "    lb=np.unique(labels) \n",
    "    classes= {} \n",
    "    for i in (lb): \n",
    "        classes[ \"class{0}\"  .format(i)] = X_temp[X_temp['labels']==i]       \n",
    "    data1=pd.concat(classes.values(), ignore_index=True)#train_test_split \n",
    "    Y=data1.iloc[:,-1] \n",
    "    X=data1.iloc[:,:-1] \n",
    "    X=X.to_numpy() \n",
    "    daX=X.copy() \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,shuffle=True,stratify=Y) \n",
    "    model2=RidgeClassifier()\n",
    "    model6=SVC(kernel='rbf',probability=True)\n",
    "    model10=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    ensemble = VotingClassifier(estimators=[('SVC', model6),('RF', model10),('Ridge', model2)], voting='hard')\n",
    "    fit_model=ensemble.fit(X_train, y_train) \n",
    "    s=fit_model.predict(X_test) \n",
    "    accuracy =balanced_accuracy_score(y_test, s) \n",
    "    conf_matrix = confusion_matrix(y_test,s)\n",
    "    if len(conf_matrix)>2:\n",
    "        tp=[]\n",
    "        fp=[]\n",
    "        tn=[]\n",
    "        fn=[]\n",
    "        for i in range(conf_matrix.shape[0]):\n",
    "            TP = conf_matrix[i, i]\n",
    "            FP = np.sum(conf_matrix[:, i]) - TP\n",
    "            FN = np.sum(conf_matrix[i, :]) - TP\n",
    "            TN = np.sum(conf_matrix) - TP - FP - FN\n",
    "            tp.append(TP)\n",
    "            fp.append(FP)\n",
    "            tn.append(TN)\n",
    "            fn.append(FN)\n",
    "        tp=np.mean(tp)\n",
    "        fp=np.mean(fp)\n",
    "        tn=np.mean(tn)\n",
    "        fn=np.mean(fn)\n",
    "    else:\n",
    "        tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    FPR=fp/(fp+tn) \n",
    "    FNR=fn/(fn+tp) \n",
    "    band_ratio= len(bands[0])/len(selected_bands) \n",
    "    return accuracy,FPR,FNR,corrsum, band_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_fn(individual,data,labels):  \n",
    "    accrcy,FPR,FNR,corrsum, band_ratio=accuracy_fn(individual,data,labels) \n",
    "    ob1=0.4*((FPR+FNR)/accrcy)\n",
    "    ob2=0.4*band_ratio \n",
    "    ob3=0.2*corrsum\n",
    "    obj_fn=ob1+ob2+ob3\n",
    "    return obj_fn,accrcy,corrsum,FPR,FNR,band_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binerization(pos):\n",
    "     k = 0\n",
    "     h = 0\n",
    "     for i in pos:\n",
    "         h = 0\n",
    "         for j in i:\n",
    "             if (j <= 0.75):\n",
    "                 pos[k, h] = 0\n",
    "             else:\n",
    "                 pos[k, h] = j\n",
    "             h+=1\n",
    "         k+=1\n",
    "     return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511fe217",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bands = X_sreduced.shape[1]\n",
    "population_size = 20\n",
    "num_generations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb3dda0",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc085cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "gamma = scipy.special.gamma\n",
    "\n",
    "def HHO(data, labels,dim, n, num_generations):\n",
    "    max_iter=num_generations\n",
    "    population = np.random.uniform(0,1, (n,dim))\n",
    "    population=binerization(population)\n",
    "    #print(population)\n",
    "    fb = np.array([objective_fn(individual,data,labels) for individual in population])\n",
    "    fitness=fb[:,0] \n",
    "    accuracy=fb[:,1] \n",
    "    corrsum=fb[:,2] \n",
    "    FPR=fb[:,3] \n",
    "    FNR=fb[:,4] \n",
    "    band_ratio=fb[:,5]\n",
    "    valid_indices = (accuracy > 0.88) & (band_ratio > 0.13) ## setting minimum accuracy 0.88 and bands 10\n",
    "\n",
    "    if np.any(valid_indices): \n",
    "        min_fitness = np.min(fitness[valid_indices])  # Minimum fitness where accuracy > 0.88\n",
    "    else:\n",
    "        min_fitness = None \n",
    "    if min_fitness is not None:\n",
    "        best_fitness = min_fitness\n",
    "        min_fitness_index = np.where(fitness == min_fitness)[0][0]\n",
    "        best_individual = population[min_fitness_index]\n",
    "        best_accuracy=accuracy[min_fitness_index]\n",
    "        best_corrsum=corrsum[min_fitness_index]\n",
    "        best_FPR=FPR[min_fitness_index]\n",
    "        best_FNR=FNR[min_fitness_index]\n",
    "        best_band_ratio=band_ratio[min_fitness_index]\n",
    "\n",
    "    \n",
    "    iteration=0\n",
    "    while iteration <=(num_generations):\n",
    "    # Levy flight\n",
    "        beta = 1.5\n",
    "        sigma = (gamma(1+beta)*np.sin(np.pi*beta/2)/(gamma((1+beta)/2)*beta*2**((beta-1)/2)))**(1/beta)\n",
    "        u = np.random.randn(n, dim)*sigma\n",
    "        v = np.random.randn(n, dim)\n",
    "        step = u/np.abs(v)**(1/beta)\n",
    "    \n",
    "    # Position update\n",
    "        population_new = population + step*(best_individual - population)\n",
    "        population_new = np.maximum(population_new, 0)\n",
    "        population_new = np.minimum(population_new, 1)\n",
    "        population_new=np.clip(population_new,0,1)\n",
    "        for individual in population_new:\n",
    "            # Check if all values in the individual are zero\n",
    "            if np.all(individual == 0):\n",
    "                # Randomly select 10 unique positions within the individual to assign non-zero values\n",
    "                indices = np.random.choice(len(individual), 10, replace=False)\n",
    "                individual[indices] = np.random.rand(10)\n",
    "\n",
    "        for i in range(n):\n",
    "            new_fb = objective_fn(population_new[i], data, labels)\n",
    "            new_fitness=new_fb[0] \n",
    "            new_accuracy=new_fb[1] \n",
    "            new_corrsum=new_fb[2] \n",
    "            new_FPR=new_fb[3] \n",
    "            new_FNR=new_fb[4] \n",
    "            new_band_ratio=new_fb[5]\n",
    "            \n",
    "            if new_fitness < fitness[i]:\n",
    "                population[i] = population_new[i]\n",
    "                fitness[i] = new_fitness\n",
    "                accuracy[i]=new_accuracy\n",
    "                corrsum[i]=new_corrsum\n",
    "                FPR[i]=new_FPR\n",
    "                FNR[i]=new_FNR\n",
    "                band_ratio[i]=new_band_ratio\n",
    "        \n",
    "        valid_indices = (accuracy > 0.88) & (band_ratio > 0.13)\n",
    "        if np.any(valid_indices): \n",
    "            min_fitness = np.min(fitness[valid_indices]) \n",
    "        else:\n",
    "            min_fitness = None  \n",
    "\n",
    "        if min_fitness is not None:\n",
    "            best_fitness = min_fitness\n",
    "            min_fitness_index = np.where(fitness == min_fitness)[0][0]\n",
    "            best_individual = population[min_fitness_index]\n",
    "            best_accuracy=accuracy[min_fitness_index]\n",
    "            best_corrsum=corrsum[min_fitness_index]\n",
    "            best_FPR=FPR[min_fitness_index]\n",
    "            best_FNR=FNR[min_fitness_index]\n",
    "            best_band_ratio=band_ratio[min_fitness_index]\n",
    "\n",
    "        print(f\"Iteration {iteration}/{max_iter}, Best fitness: {best_fitness}, Best accuracy: {best_accuracy}, No. of bands: {len(best_individual[best_individual != 0])}\")      \n",
    "        iteration +=1\n",
    "\n",
    "    return best_individual, best_accuracy, best_corrsum, best_FPR, best_FNR, best_band_ratio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9faa778",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_hho = time.time()\n",
    "best_individual_hho,accuracy_hho,best_corrsum,best_FPR,best_FNR,best_band_ratio= HHO(sampled_data_reduced, sampled_labels_reduced,num_bands, population_size, num_generations)\n",
    "bi_hho=np.where(best_individual_hho!=0)\n",
    "final_bands_hho=selected_bands[bi_hho[0]]\n",
    "final_wv_hho= {k: selected_values[k] for k in final_bands_hho if k in selected_values}\n",
    "X_im_hho=X_s[:,final_bands_hho]\n",
    "end_time_hho = time.time()\n",
    "total_time_hho = end_time_hho - start_time_hho\n",
    "print(\"Time of operation:\", total_time_hho, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ca6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best band combination\", best_individual_hho)\n",
    "print(\"Best_accuracy\", accuracy_hho)\n",
    "print(\"Best_corrsum\", best_corrsum)\n",
    "print(\"Best_FPR\", best_FPR)\n",
    "print(\"Best_FNR\", best_FNR)\n",
    "print(\"Best_band_ratio\", best_band_ratio )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690db11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_hho1=[]\n",
    "array_hho2=[]\n",
    "array_hho3=[]\n",
    "array_hho4=[]\n",
    "array_hho5=[]\n",
    "array_hho6=[]\n",
    "\n",
    "for i in range(0,len(final_wv_hho)):\n",
    "    if 450<=(list(final_wv_hho.values())[i])<550:\n",
    "        array_hho1.append(list(final_wv_hho.values())[i])\n",
    "    if 550<=(list(final_wv_hho.values())[i])<650:\n",
    "        array_hho2.append(list(final_wv_hho.values())[i])\n",
    "    if 650<=(list(final_wv_hho.values())[i])<750:\n",
    "        array_hho3.append(list(final_wv_hho.values())[i])\n",
    "    if 750<=(list(final_wv_hho.values())[i])<850:\n",
    "        array_hho4.append(list(final_wv_hho.values())[i])\n",
    "    if 850<=(list(final_wv_hho.values())[i])<950:\n",
    "        array_hho5.append(list(final_wv_hho.values())[i])\n",
    "    if 950<=(list(final_wv_hho.values())[i])<1050:\n",
    "        array_hho6.append(list(final_wv_hho.values())[i])\n",
    "        \n",
    "print(\"\\n hho wavelengths:\\n\")       \n",
    "print(\"Wavelengths in range 450-550 nm:\", array_hho1)\n",
    "print(\"Wavelengths in range 550-650 nm:\", array_hho2)\n",
    "print(\"Wavelengths in range 650-750 nm:\", array_hho3)\n",
    "print(\"Wavelengths in range 750-850 nm:\", array_hho4)\n",
    "print(\"Wavelengths in range 850-950 nm:\", array_hho5)\n",
    "print(\"Wavelengths in range 950-1050 nm:\", array_hho6)\n",
    "\n",
    "print(\"Wavelengths in range 450-550 nm:\",len(array_hho1))\n",
    "print(\"Wavelengths in range 550-650 nm:\", len(array_hho2))\n",
    "print(\"Wavelengths in range 650-750 nm:\", len(array_hho3))\n",
    "print(\"Wavelengths in range 750-850 nm:\",len (array_hho4))\n",
    "print(\"Wavelengths in range 850-950 nm:\",len (array_hho5))\n",
    "print(\"Wavelengths in range 950-1050 nm:\",len (array_hho6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26699bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MPA\n",
    "\n",
    "# MPA Parameters\n",
    "RB = 0.5       # Random bound factor for steps\n",
    "RL = 0.8       # Different bound factor for step size adjustment\n",
    "P = 0.5        # Predator/prey interaction factor\n",
    "CF = 0.5       # A coefficient factor affecting step size\n",
    "#Max_Iter = 100 # Max number of iterations\n",
    "FADs = 0.2     # FADs threshold for selective exploitation\n",
    "Xmin, Xmax = 0,1  # Define boundaries for dimensions\n",
    "\n",
    "# Update functions based on MPA equations\n",
    "def update_prey_phase1(prey, elite, step_size):\n",
    "    return prey + P * np.random.rand(*prey.shape) * step_size\n",
    "\n",
    "def update_prey_phase2_first_half(prey, elite, step_size):\n",
    "    return prey + P * np.random.rand(*prey.shape) * step_size\n",
    "\n",
    "def update_prey_phase2_second_half(prey, elite, step_size):\n",
    "    return elite + P * CF * step_size\n",
    "\n",
    "# Exploitation phase (Eq. 15)\n",
    "def update_prey_phase3(prey, elite):\n",
    "    step_size = RL * (elite - prey)\n",
    "    return elite + P * CF * step_size\n",
    "\n",
    "# FADs Effect (Eq. 16)\n",
    "def apply_fads_effect(prey, Xmin, Xmax):\n",
    "    r = np.random.rand()\n",
    "    if r <= FADs:\n",
    "        # First condition\n",
    "        return prey + CF * (Xmin + np.random.rand() * (Xmax - Xmin))\n",
    "    else:\n",
    "        # Second condition\n",
    "        r1, r2 = np.random.randint(0, len(prey), size=2)  # Random prey indices for r1, r2\n",
    "        return prey + (FADs * (1 - r) + r) * (prey[r1] - prey[r2])\n",
    "\n",
    "def marine_predators_algorithm(data, labels,num_bands, pop_size, Max_iter):\n",
    "    # Initialize prey positions and fitness\n",
    "    population = np.random.uniform(0,1, (pop_size,num_bands))\n",
    "    population=binerization(population)\n",
    "    fb = np.array([objective_fn(individual, data, labels) for individual in population])\n",
    "    fitness=fb[:,0] \n",
    "    accuracy=fb[:,1] \n",
    "    corrsum=fb[:,2] \n",
    "    FPR=fb[:,3] \n",
    "    FNR=fb[:,4] \n",
    "    band_ratio=fb[:,5]\n",
    "    elite_index = np.argmin(fitness)\n",
    "    elite = population[elite_index]\n",
    "    Max_Iter=num_generations\n",
    "    valid_indices = (accuracy > 0.88) & (band_ratio > 0.13)\n",
    "    if np.any(valid_indices): \n",
    "        min_fitness = np.min(fitness[valid_indices]) \n",
    "    else:\n",
    "        min_fitness = None  \n",
    "\n",
    "    if min_fitness is not None:\n",
    "        best_fitness = min_fitness\n",
    "        min_fitness_index = np.where(fitness == min_fitness)[0][0]\n",
    "        best_individual = population[min_fitness_index]\n",
    "        best_accuracy=accuracy[min_fitness_index]\n",
    "        best_corrsum=corrsum[min_fitness_index]\n",
    "        best_FPR=FPR[min_fitness_index]\n",
    "        best_FNR=FNR[min_fitness_index]\n",
    "        best_band_ratio=band_ratio[min_fitness_index]\n",
    "\n",
    "\n",
    "    for iteration in range(Max_Iter):\n",
    "        step_size = np.random.rand(pop_size, num_bands)\n",
    "\n",
    "        # Phase 1: Initial exploration\n",
    "        if iteration < Max_Iter / 3:\n",
    "            for i in range(pop_size):\n",
    "                step_size[i] = RB * (elite - population[i])\n",
    "                population[i] = update_prey_phase1(population[i], elite, step_size[i])\n",
    "\n",
    "        # Phase 2: Transition from exploration to exploitation\n",
    "        elif iteration < 2 * Max_Iter / 3:\n",
    "            for i in range(pop_size // 2):\n",
    "                step_size[i] = RL * (elite - population[i])\n",
    "                population[i] = update_prey_phase2_first_half(population[i], elite, step_size[i])\n",
    "\n",
    "            for i in range(pop_size // 2, pop_size):\n",
    "                step_size[i] = RB * (elite - population[i])\n",
    "                population[i] = update_prey_phase2_second_half(population[i], elite, step_size[i])\n",
    "\n",
    "        # Phase 3: Intensified exploitation near elite solution (Eq. 15)\n",
    "        else:\n",
    "            for i in range(pop_size):\n",
    "                population[i] = update_prey_phase3(population[i], elite)\n",
    "\n",
    "        # Apply FADs effect for selective exploitation (Eq. 16)\n",
    "        for i in range(pop_size):\n",
    "            population[i] = apply_fads_effect(population[i], Xmin, Xmax)\n",
    "\n",
    "        # Update fitness and elite\n",
    "        population=np.clip(population, 0,1)\n",
    "        for individual in population:\n",
    "            # Check if all values in the individual are zero\n",
    "            if np.all(individual == 0):\n",
    "                # Randomly select 10 unique positions within the individual to assign non-zero values\n",
    "                indices = np.random.choice(len(individual), 10, replace=False)\n",
    "                individual[indices] = np.random.rand(10)\n",
    "\n",
    "        fb = np.array([objective_fn(individual, data, labels) for individual in population])\n",
    "        fitness=fb[:,0] \n",
    "        accuracy=fb[:,1] \n",
    "        corrsum=fb[:,2] \n",
    "        FPR=fb[:,3] \n",
    "        FNR=fb[:,4] \n",
    "        band_ratio=fb[:,5]\n",
    "        valid_indices= (accuracy > 0.88) & (band_ratio > 0.13)\n",
    "        if np.any(valid_indices):  \n",
    "            min_fitness = np.min(fitness[valid_indices]) \n",
    "        else:\n",
    "            min_fitness = None \n",
    "\n",
    "        if min_fitness is not None:\n",
    "            best_fitness = min_fitness\n",
    "            min_fitness_index = np.where(fitness == min_fitness)[0][0]\n",
    "            best_individual = population[min_fitness_index]\n",
    "            best_accuracy=accuracy[min_fitness_index]\n",
    "            best_corrsum=corrsum[min_fitness_index]\n",
    "            best_FPR=FPR[min_fitness_index]\n",
    "            best_FNR=FNR[min_fitness_index]\n",
    "            best_band_ratio=band_ratio[min_fitness_index]\n",
    "            #elite_index = np.argmin(fitness)\n",
    "        \n",
    "        new_fb = objective_fn(elite, data, labels)\n",
    "        new_fitness=new_fb[0] \n",
    "        new_accuracy=new_fb[1] \n",
    "        new_corrsum=new_fb[2] \n",
    "        new_FPR=new_fb[3] \n",
    "        new_FNR=new_fb[4] \n",
    "        new_band_ratio=new_fb[5]\n",
    "        \n",
    "        if fitness[min_fitness_index]<new_fitness:\n",
    "            elite = population[min_fitness_index]\n",
    "            best_fitness=min_fitness\n",
    "            best_accuracy=accuracy[min_fitness_index]\n",
    "            best_corrsum=corrsum[min_fitness_index]\n",
    "            best_FPR=FPR[min_fitness_index]\n",
    "            best_FNR=FNR[min_fitness_index]\n",
    "            best_band_ratio=band_ratio[min_fitness_index]\n",
    "        else:\n",
    "            elite=elite\n",
    "            best_fitness=new_fitness\n",
    "            best_accuracy=new_accuracy\n",
    "            best_corrsum=new_corrsum\n",
    "            best_FPR=new_FPR\n",
    "            best_FNR=new_FNR\n",
    "            best_band_ratio=new_band_ratio\n",
    "\n",
    "        print(f\"Iteration {iteration + 1}/{Max_Iter}, Best fitness: {best_fitness}, best_accuracy: {best_accuracy}, bands: {len(elite[elite!=0])}\")\n",
    "\n",
    "        \n",
    "    return elite, best_accuracy, best_corrsum, best_FPR, best_FNR, best_band_ratio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1af883",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_mpa = time.time()\n",
    "best_individual_mpa,accuracy_mpa,best_corrsum,best_FPR,best_FNR,best_band_ratio= marine_predators_algorithm(sampled_data_reduced, sampled_labels_reduced,num_bands, population_size, num_generations)\n",
    "bi_mpa=np.where(best_individual_mpa!=0)\n",
    "final_bands_mpa=selected_bands[bi_mpa[0]]\n",
    "final_wv_mpa= {k: selected_values[k] for k in final_bands_mpa if k in selected_values}\n",
    "X_im_mpa=X_s[:,final_bands_mpa]\n",
    "end_time_mpa = time.time()\n",
    "total_time_mpa = end_time_mpa - start_time_mpa\n",
    "print(\"Time of operation:\", total_time_mpa, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d06dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best band combination\", best_individual_mpa)\n",
    "print(\"Best_accuracy\", accuracy_mpa)\n",
    "print(\"Best_corrsum\", best_corrsum)\n",
    "print(\"Best_FPR\", best_FPR)\n",
    "print(\"Best_FNR\", best_FNR)\n",
    "print(\"Best_band_ratio\", best_band_ratio )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76968eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_mpa1=[]\n",
    "array_mpa2=[]\n",
    "array_mpa3=[]\n",
    "array_mpa4=[]\n",
    "array_mpa5=[]\n",
    "array_mpa6=[]\n",
    "\n",
    "for i in range(0,len(final_wv_mpa)):\n",
    "    if 450<=(list(final_wv_mpa.values())[i])<550:\n",
    "        array_mpa1.append(list(final_wv_mpa.values())[i])\n",
    "    if 550<=(list(final_wv_mpa.values())[i])<650:\n",
    "        array_mpa2.append(list(final_wv_mpa.values())[i])\n",
    "    if 650<=(list(final_wv_mpa.values())[i])<750:\n",
    "        array_mpa3.append(list(final_wv_mpa.values())[i])\n",
    "    if 750<=(list(final_wv_mpa.values())[i])<850:\n",
    "        array_mpa4.append(list(final_wv_mpa.values())[i])\n",
    "    if 850<=(list(final_wv_mpa.values())[i])<950:\n",
    "        array_mpa5.append(list(final_wv_mpa.values())[i])\n",
    "    if 950<=(list(final_wv_mpa.values())[i])<1050:\n",
    "        array_mpa6.append(list(final_wv_mpa.values())[i])\n",
    "        \n",
    "print(\"\\n mpa wavelengths:\\n\")       \n",
    "print(\"Wavelengths in range 450-550 nm:\", array_mpa1)\n",
    "print(\"Wavelengths in range 550-650 nm:\", array_mpa2)\n",
    "print(\"Wavelengths in range 650-750 nm:\", array_mpa3)\n",
    "print(\"Wavelengths in range 750-850 nm:\", array_mpa4)\n",
    "print(\"Wavelengths in range 850-950 nm:\", array_mpa5)\n",
    "print(\"Wavelengths in range 950-1050 nm:\", array_mpa6)\n",
    "\n",
    "print(\"Wavelengths in range 450-550 nm:\",len(array_mpa1))\n",
    "print(\"Wavelengths in range 550-650 nm:\", len(array_mpa2))\n",
    "print(\"Wavelengths in range 650-750 nm:\", len(array_mpa3))\n",
    "print(\"Wavelengths in range 750-850 nm:\",len (array_mpa4))\n",
    "print(\"Wavelengths in range 850-950 nm:\",len (array_mpa5))\n",
    "print(\"Wavelengths in range 950-1050 nm:\",len (array_mpa6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e403797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HBA\n",
    "\n",
    "# Main Honey Badger Algorithm\n",
    "def honey_badger_algorithm(data, labels,num_bands, population_size, tmax):\n",
    "    population = np.random.uniform(0,1, (population_size, num_bands))\n",
    "    population=binerization(population)\n",
    "    fb = np.array([objective_fn(individual,data,labels) for individual in population])\n",
    "    fitness=fb[:,0] \n",
    "    accuracy=fb[:,1] \n",
    "    corrsum=fb[:,2] \n",
    "    FPR=fb[:,3] \n",
    "    FNR=fb[:,4] \n",
    "    band_ratio=fb[:,5]\n",
    "    best_idx = np.argmin(fitness)\n",
    "    xprey = population[best_idx].copy()\n",
    "    fprey = fitness[best_idx]\n",
    "    #print(\"Fprey\", fprey)\n",
    "    best_accuracy=accuracy[best_idx]\n",
    "    best_corrsum=corrsum[best_idx]\n",
    "    best_FPR=FPR[best_idx]\n",
    "    best_FNR=FNR[best_idx]\n",
    "    best_band_ratio=band_ratio[best_idx]\n",
    "    \n",
    "\n",
    "    t = 0\n",
    "    beta=6\n",
    "    C=2\n",
    "    while t <= tmax:\n",
    "        # Update the decreasing factor Î±\n",
    "        alpha = np.exp(-t / tmax)\n",
    "        \n",
    "        for i in range(population_size):\n",
    "            # Calculate intensity I\n",
    "            I = alpha * (beta * np.exp(-C * (t / tmax)) - np.random.rand())\n",
    "\n",
    "            # Random number r between 0 and 1\n",
    "            r = np.random.rand()\n",
    "\n",
    "            # Update position \n",
    "            if r < 0.5:\n",
    "                xnew = population[i] + I * (xprey - population[i]) + alpha * (1 - 0) * np.random.rand(num_bands)\n",
    "            else:\n",
    "                # Exploitation (Eq. 6)\n",
    "                xnew = xprey + I * (population[i] - xprey)\n",
    "            \n",
    "            # Ensure new position is within bounds\n",
    "            xnew = np.clip(xnew, 0,1)\n",
    "\n",
    "            # Evaluate fitness of the new position\n",
    "            fb_new = objective_fn(xnew,data,labels)\n",
    "            #print(fb_new)\n",
    "            fitness_new=fb_new[0] \n",
    "            print(\"Fitness_new\", fitness_new)\n",
    "            accuracy_new=fb_new[1] \n",
    "            corrsum_new=fb_new[2] \n",
    "            FPR_new=fb_new[3] \n",
    "            FNR_new=fb_new[4] \n",
    "            band_ratio_new=fb_new[5]\n",
    "\n",
    "            # Update if new position is better\n",
    "            if fitness_new < fitness[i]:\n",
    "                population[i] = xnew\n",
    "                fitness[i] = fitness_new\n",
    "                accuracy[i]=accuracy_new\n",
    "                corrsum[i]=corrsum_new\n",
    "                FPR[i]=FPR_new\n",
    "                FNR[i]=FNR_new\n",
    "                band_ratio[i]=band_ratio_new\n",
    "\n",
    "            # Update global best \n",
    "            if fitness_new < fprey:\n",
    "                xprey = xnew\n",
    "                fprey = fitness_new\n",
    "                best_accuracy=accuracy_new\n",
    "                best_corrsum=corrsum_new\n",
    "                best_FPR=FPR_new\n",
    "                best_FNR=FNR_new\n",
    "                best_band_ratio=band_ratio_new\n",
    "            #bf.append(fitness_new)\n",
    "        \n",
    "        print (\"Iter = \" + str(t) + \"Completed \" + \" best_fitness\" + str(fprey) + \"best_accuracy\" + str(best_accuracy) + \"bands\" + str(len(np.where(xprey!=0)[0])))\n",
    "        t += 1\n",
    "\n",
    "    # Return the best solution found\n",
    "    return xprey, best_accuracy, best_corrsum, best_FPR, best_FNR,best_band_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3070f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_hba = time.time()\n",
    "best_individual_hba,accuracy_hba,best_corrsum,best_FPR,best_FNR,best_band_ratio = honey_badger_algorithm(sampled_data_reduced, sampled_labels_reduced,num_bands, population_size, num_generations)\n",
    "bi_hba=np.where(best_individual_hba!=0)\n",
    "final_bands_hba=selected_bands[bi_hba[0]]\n",
    "final_wv_hba= {k: selected_values[k] for k in final_bands_hba if k in selected_values}\n",
    "X_im_hba=X_s[:,final_bands_hba]\n",
    "\n",
    "end_time_hba = time.time()\n",
    "total_time_hba = end_time_hba - start_time_hba\n",
    "print(\"Time of operation:\", total_time_hba, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f845d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best band combination\", best_individual_hba)\n",
    "print(\"Best_accuracy\", accuracy_hba)\n",
    "print(\"Best_corrsum\", best_corrsum)\n",
    "print(\"Best_FPR\", best_FPR)\n",
    "print(\"Best_FNR\", best_FNR)\n",
    "print(\"Best_band_ratio\", best_band_ratio )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d70c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_hba1=[]\n",
    "array_hba2=[]\n",
    "array_hba3=[]\n",
    "array_hba4=[]\n",
    "array_hba5=[]\n",
    "array_hba6=[]\n",
    "\n",
    "for i in range(0,len(final_wv_hba)):\n",
    "    if 450<=(list(final_wv_hba.values())[i])<550:\n",
    "        array_hba1.append(list(final_wv_hba.values())[i])\n",
    "    if 550<=(list(final_wv_hba.values())[i])<650:\n",
    "        array_hba2.append(list(final_wv_hba.values())[i])\n",
    "    if 650<=(list(final_wv_hba.values())[i])<750:\n",
    "        array_hba3.append(list(final_wv_hba.values())[i])\n",
    "    if 750<=(list(final_wv_hba.values())[i])<850:\n",
    "        array_hba4.append(list(final_wv_hba.values())[i])\n",
    "    if 850<=(list(final_wv_hba.values())[i])<950:\n",
    "        array_hba5.append(list(final_wv_hba.values())[i])\n",
    "    if 950<=(list(final_wv_hba.values())[i])<1050:\n",
    "        array_hba6.append(list(final_wv_hba.values())[i])\n",
    "        \n",
    "print(\"\\n hba wavelengths:\\n\")       \n",
    "print(\"Wavelengths in range 450-550 nm:\", array_hba1)\n",
    "print(\"Wavelengths in range 550-650 nm:\", array_hba2)\n",
    "print(\"Wavelengths in range 650-750 nm:\", array_hba3)\n",
    "print(\"Wavelengths in range 750-850 nm:\", array_hba4)\n",
    "print(\"Wavelengths in range 850-950 nm:\", array_hba5)\n",
    "print(\"Wavelengths in range 950-1050 nm:\", array_hba6)\n",
    "\n",
    "print(\"Wavelengths in range 450-550 nm:\",len(array_hba1))\n",
    "print(\"Wavelengths in range 550-650 nm:\", len(array_hba2))\n",
    "print(\"Wavelengths in range 650-750 nm:\", len(array_hba3))\n",
    "print(\"Wavelengths in range 750-850 nm:\",len (array_hba4))\n",
    "print(\"Wavelengths in range 850-950 nm:\",len (array_hba5))\n",
    "print(\"Wavelengths in range 950-1050 nm:\",len (array_hba6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Feeding strategy (exploration) to update position (Eq. 3)\n",
    "def feeding_strategy(current_walrus, strongest_walrus, lb, ub):\n",
    "    new_position = current_walrus + np.random.rand() * (strongest_walrus - current_walrus)\n",
    "    return np.clip(new_position, lb, ub)\n",
    "\n",
    "# Migration strategy (Eq. 5 and Eq. 6)\n",
    "def migration_strategy(current_walrus, lb, ub, dim):\n",
    "    immigration_destination = np.random.uniform(lb, ub, dim)\n",
    "    new_position = current_walrus + np.random.rand() * (immigration_destination - current_walrus)\n",
    "    return np.clip(new_position, lb, ub)\n",
    "\n",
    "# Escaping and fighting predators (exploitation) to update position (Eq. 7, 8, 9)\n",
    "def predator_escape_strategy(current_walrus, strongest_walrus, lb, ub):\n",
    "    new_position = current_walrus + np.random.rand() * (current_walrus - strongest_walrus)\n",
    "    return np.clip(new_position, lb, ub)\n",
    "\n",
    "def walrus_optimization(data, labels,num_bands, population_size, num_generations):\n",
    "    population = np.random.uniform(0,1, (population_size, num_bands))\n",
    "    population=binerization(population)\n",
    "    print(population)\n",
    "    fb = np.array([objective_fn(individual, data,labels ) for individual in population])\n",
    "    fitness=fb[:,0] \n",
    "    accuracy=fb[:,1] \n",
    "    corrsum=fb[:,2] \n",
    "    FPR=fb[:,3] \n",
    "    FNR=fb[:,4] \n",
    "    band_ratio=fb[:,5]\n",
    "    # Step 2: Find the strongest walrus (best solution)\n",
    "    best_walrus = population[np.argmin(fitness)]\n",
    "    best_fitness = np.min(fitness)\n",
    "    print(\"best_fitness: \", best_fitness)\n",
    "    best_accuracy=accuracy[np.argmin(fitness)] \n",
    "    best_corrsum=corrsum[np.argmin(fitness)] \n",
    "    best_FPR=FPR[np.argmin(fitness)] \n",
    "    best_FNR=FNR[np.argmin(fitness)] \n",
    "    best_band_ratio=band_ratio[np.argmin(fitness)]\n",
    "    t=0\n",
    "    # Main loop for iterations\n",
    "    while t <=num_generations:\n",
    "        for i in range(population_size):\n",
    "            \n",
    "            new_walrus = feeding_strategy(population[i], best_walrus, 0, 1)\n",
    "            new_fb = objective_fn(new_walrus, data, labels)\n",
    "            new_fitness=new_fb[0]\n",
    "            new_accuracy=new_fb[1]\n",
    "            new_corrsum=new_fb[2]\n",
    "            new_FPR=new_fb[3]\n",
    "            new_FNR=new_fb[4]\n",
    "            new_band_ratio=new_fb[5]\n",
    "            \n",
    "            if new_fitness < fitness[i]:  # Update if new fitness is better\n",
    "                population[i] = new_walrus\n",
    "                fitness[i] = new_fitness\n",
    "                accuracy[i]=new_accuracy\n",
    "                corrsum[i]=new_corrsum\n",
    "                FPR[i]=new_FPR\n",
    "                FNR[i]=new_FNR\n",
    "                band_ratio[i]=new_band_ratio\n",
    "            # Phase 2: Migration strategy\n",
    "            new_walrus = migration_strategy(population[i], 0, 1, num_bands)\n",
    "            new_fb = objective_fn(new_walrus, data, labels)\n",
    "            new_fitness=new_fb[0]\n",
    "            new_accuracy=new_fb[1]\n",
    "            new_corrsum=new_fb[2]\n",
    "            new_FPR=new_fb[3]\n",
    "            new_FNR=new_fb[4]\n",
    "            new_band_ratio=new_fb[5]\n",
    "\n",
    "            if new_fitness < fitness[i]:  # Update if new fitness is better\n",
    "                population[i] = new_walrus\n",
    "                fitness[i] = new_fitness\n",
    "                accuracy[i]=new_accuracy\n",
    "                corrsum[i]=new_corrsum\n",
    "                FPR[i]=new_FPR\n",
    "                FNR[i]=new_FNR\n",
    "                band_ratio[i]=new_band_ratio\n",
    "\n",
    "            # Phase 3: Predator escape strategy (exploitation)\n",
    "            new_walrus = predator_escape_strategy(population[i], best_walrus, 0, 1)\n",
    "            new_fb = objective_fn(new_walrus, data, labels)\n",
    "            new_fitness=new_fb[0]\n",
    "            new_accuracy=new_fb[1]\n",
    "            new_corrsum=new_fb[2]\n",
    "            new_FPR=new_fb[3]\n",
    "            new_FNR=new_fb[4]\n",
    "            new_band_ratio=new_fb[5]\n",
    "\n",
    "            if new_fitness < fitness[i]:  # Update if new fitness is better\n",
    "                population[i] = new_walrus\n",
    "                fitness[i] = new_fitness\n",
    "                accuracy[i]=new_accuracy\n",
    "                corrsum[i]=new_corrsum\n",
    "                FPR[i]=new_FPR\n",
    "                FNR[i]=new_FNR\n",
    "                band_ratio[i]=new_band_ratio\n",
    "\n",
    "            # Update the global best solution if needed\n",
    "            if fitness[i] < best_fitness:\n",
    "                best_fitness = fitness[i]\n",
    "                best_walrus = population[i]\n",
    "                best_accuracy=accuracy[i] \n",
    "                best_corrsum=corrsum[i] \n",
    "                best_FPR=FPR[i] \n",
    "                best_FNR=FNR[i] \n",
    "                best_band_ratio=band_ratio[i]  \n",
    "            \n",
    "        print(f'Iteration{t}, best_fitness: {best_fitness}, best_accuracy: {best_accuracy}')\n",
    "        t +=1\n",
    "    return best_walrus, best_accuracy, best_corrsum, best_FPR, best_FNR, best_band_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_waoa = time.time()\n",
    "best_individual_waoa,accuracy_waoa,best_corrsum,best_FPR,best_FNR,best_band_ratio = walrus_optimization(X_sreduced, labels,num_bands, population_size, num_generations)\n",
    "bi_waoa=np.where(best_individual_waoa!=0)\n",
    "final_bands_waoa=selected_bands[bi_waoa[0]]\n",
    "final_wv_waoa= {k: selected_values[k] for k in final_bands_waoa if k in selected_values}\n",
    "X_im_waoa=X_s[:,final_bands_waoa]\n",
    "\n",
    "end_time_waoa = time.time()\n",
    "total_time_waoa = end_time_waoa - start_time_waoa\n",
    "print(\"Time of operation:\", total_time_waoa, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best band combination\", best_individual_waoa)\n",
    "print(\"Best_accuracy\", accuracy_waoa)\n",
    "print(\"Best_corrsum\", best_corrsum)\n",
    "print(\"Best_FPR\", best_FPR)\n",
    "print(\"Best_FNR\", best_FNR)\n",
    "print(\"Best_band_ratio\", best_band_ratio )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178875f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_waoa1=[]\n",
    "array_waoa2=[]\n",
    "array_waoa3=[]\n",
    "array_waoa4=[]\n",
    "array_waoa5=[]\n",
    "array_waoa6=[]\n",
    "\n",
    "for i in range(0,len(final_wv_waoa)):\n",
    "    if 450<=(list(final_wv_waoa.values())[i])<550:\n",
    "        array_waoa1.append(list(final_wv_waoa.values())[i])\n",
    "    if 550<=(list(final_wv_waoa.values())[i])<650:\n",
    "        array_waoa2.append(list(final_wv_waoa.values())[i])\n",
    "    if 650<=(list(final_wv_waoa.values())[i])<750:\n",
    "        array_waoa3.append(list(final_wv_waoa.values())[i])\n",
    "    if 750<=(list(final_wv_waoa.values())[i])<850:\n",
    "        array_waoa4.append(list(final_wv_waoa.values())[i])\n",
    "    if 850<=(list(final_wv_waoa.values())[i])<950:\n",
    "        array_waoa5.append(list(final_wv_waoa.values())[i])\n",
    "    if 950<=(list(final_wv_waoa.values())[i])<1050:\n",
    "        array_waoa6.append(list(final_wv_waoa.values())[i])\n",
    "        \n",
    "print(\"\\n waoa wavelengths:\\n\")       \n",
    "print(\"Wavelengths in range 450-550 nm:\", array_waoa1)\n",
    "print(\"Wavelengths in range 550-650 nm:\", array_waoa2)\n",
    "print(\"Wavelengths in range 650-750 nm:\", array_waoa3)\n",
    "print(\"Wavelengths in range 750-850 nm:\", array_waoa4)\n",
    "print(\"Wavelengths in range 850-950 nm:\", array_waoa5)\n",
    "print(\"Wavelengths in range 950-1050 nm:\", array_waoa6)\n",
    "\n",
    "print(\"Wavelengths in range 450-550 nm:\",len(array_waoa1))\n",
    "print(\"Wavelengths in range 550-650 nm:\", len(array_waoa2))\n",
    "print(\"Wavelengths in range 650-750 nm:\", len(array_waoa3))\n",
    "print(\"Wavelengths in range 750-850 nm:\",len (array_waoa4))\n",
    "print(\"Wavelengths in range 850-950 nm:\",len (array_waoa5))\n",
    "print(\"Wavelengths in range 950-1050 nm:\",len (array_waoa6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a6591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOA\n",
    "def BOA(data, labels,num_bands, population_size, num_generations):\n",
    "    population = np.random.uniform(0,1, (population_size, num_bands))\n",
    "    population=binerization(population)\n",
    "    #print(population)\n",
    "    fb = np.array([objective_fn(individual, data, labels) for individual in population])\n",
    "    fitness=fb[:,0] \n",
    "    accuracy=fb[:,1] \n",
    "    corrsum=fb[:,2] \n",
    "    FPR=fb[:,3] \n",
    "    FNR=fb[:,4] \n",
    "    band_ratio=fb[:,5]\n",
    "    \n",
    "    max_iter=num_generations\n",
    "    iteration=0\n",
    "    # Main loop for BOA\n",
    "    while iteration <= max_iter:\n",
    "        for i in range(population_size):\n",
    "            # Phase 1: Tracking and moving towards prey\n",
    "            preys = [population[j] for j in range(population_size) if fitness[j] < fitness[i] and j != i]\n",
    "            #termite_mounds = np.random.choice(population, size=int(population_size / 2), replace=False)\n",
    "            termite_mounds = population[np.random.choice(population_size, size=int(population_size / 2), replace=False)]         \n",
    "            if preys:  # Only update if there are better preys\n",
    "                population[i] = population[i] + (1 - 2 * np.random.rand()) * (np.mean(preys, axis=0) - termite_mounds[0])\n",
    "                population[i]=np.clip(population[i],0,1)\n",
    "            # Update fitness after phase 1\n",
    "            new_fb= objective_fn(population[i], data, labels)\n",
    "            new_fitness=new_fb[0] \n",
    "            new_accuracy=new_fb[1] \n",
    "            new_corrsum=new_fb[2] \n",
    "            new_FPR=new_fb[3] \n",
    "            new_FNR=new_fb[4] \n",
    "            new_band_ratio=new_fb[5]\n",
    "            \n",
    "            if new_fitness < fitness[i]:\n",
    "                fitness[i] = new_fitness\n",
    "                accuracy[i]=new_accuracy\n",
    "                corrsum[i]=new_corrsum\n",
    "                FPR[i]=new_FPR\n",
    "                FNR[i]=new_FNR\n",
    "                band_ratio[i]=new_band_ratio\n",
    "\n",
    "            # Phase 2: Chasing the prey\n",
    "            population[i] = population[i] + np.random.rand() * (population[i] - np.mean(population, axis=0))\n",
    "            population[i]=np.clip(population[i],0,1)\n",
    "            # Update fitness after phase 2\n",
    "            new_fb = objective_fn(population[i], data, labels)\n",
    "            new_fitness=new_fb[0] \n",
    "            new_accuracy=new_fb[1] \n",
    "            new_corrsum=new_fb[2] \n",
    "            new_FPR=new_fb[3] \n",
    "            new_FNR=new_fb[4] \n",
    "            new_band_ratio=new_fb[5]\n",
    "            \n",
    "            if new_fitness < fitness[i]:\n",
    "                fitness[i] = new_fitness\n",
    "                accuracy[i]=new_accuracy\n",
    "                corrsum[i]=new_corrsum\n",
    "                FPR[i]=new_FPR\n",
    "                FNR[i]=new_FNR\n",
    "                band_ratio[i]=new_band_ratio\n",
    "\n",
    "        # Print iteration progress (optional)\n",
    "        best_fitness = np.min(fitness)\n",
    "        best_solution=population[np.argmin(fitness)]\n",
    "        best_accuracy= accuracy[np.argmin(fitness)]\n",
    "        best_corrsum=corrsum[np.argmin(fitness)]\n",
    "        best_FPR=FPR[np.argmin(fitness)]\n",
    "        best_FNR=FNR[np.argmin(fitness)]\n",
    "        best_band_ratio=band_ratio[np.argmin(fitness)]\n",
    "        print(f\"Iteration {iteration}/{max_iter}, Best fitness: {best_fitness}, Best accuracy: {best_accuracy}, No. of bands: {len(np.where(population!=0))}\")\n",
    "        iteration +=1\n",
    "    # Find and return the best solution\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best_fitness=fitness[best_idx]\n",
    "    best_solution = population[best_idx]\n",
    "    best_accuracy=accuracy[best_idx]\n",
    "    best_corrsum=corrsum[best_idx]\n",
    "    best_FPR=FPR[best_idx]\n",
    "    best_FNR=FNR[best_idx]\n",
    "    best_band_ratio=band_ratio[best_idx]\n",
    "    \n",
    "    return best_solution, best_accuracy, best_corrsum, best_FPR, best_FNR, best_band_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a825e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_boa = time.time()\n",
    "best_individual_boa,accuracy_boa,best_corrsum,best_FPR,best_FNR,best_band_ratio= BOA(sampled_data_reduced, sampled_labels_reduced,num_bands, population_size, num_generations)\n",
    "bi_boa=np.where(best_individual_boa!=0)\n",
    "final_bands_boa=selected_bands[bi_boa[0]]\n",
    "final_wv_boa= {k: selected_values[k] for k in final_bands_boa if k in selected_values}\n",
    "X_im_boa=X_s[:,final_bands_boa]\n",
    "end_time_boa = time.time()\n",
    "total_time_boa = end_time_boa - start_time_boa\n",
    "print(\"Time of operation:\", total_time_boa, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best band combination\", best_individual_boa)\n",
    "print(\"Best_accuracy\", accuracy_boa)\n",
    "print(\"Best_corrsum\", best_corrsum)\n",
    "print(\"Best_FPR\", best_FPR)\n",
    "print(\"Best_FNR\", best_FNR)\n",
    "print(\"Best_band_ratio\", best_band_ratio )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfd0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_boa1=[]\n",
    "array_boa2=[]\n",
    "array_boa3=[]\n",
    "array_boa4=[]\n",
    "array_boa5=[]\n",
    "array_boa6=[]\n",
    "\n",
    "for i in range(0,len(final_wv_boa)):\n",
    "    if 450<=(list(final_wv_boa.values())[i])<550:\n",
    "        array_boa1.append(list(final_wv_boa.values())[i])\n",
    "    if 550<=(list(final_wv_boa.values())[i])<650:\n",
    "        array_boa2.append(list(final_wv_boa.values())[i])\n",
    "    if 650<=(list(final_wv_boa.values())[i])<750:\n",
    "        array_boa3.append(list(final_wv_boa.values())[i])\n",
    "    if 750<=(list(final_wv_boa.values())[i])<850:\n",
    "        array_boa4.append(list(final_wv_boa.values())[i])\n",
    "    if 850<=(list(final_wv_boa.values())[i])<950:\n",
    "        array_boa5.append(list(final_wv_boa.values())[i])\n",
    "    if 950<=(list(final_wv_boa.values())[i])<1050:\n",
    "        array_boa6.append(list(final_wv_boa.values())[i])\n",
    "        \n",
    "print(\"\\n boa wavelengths:\\n\")       \n",
    "print(\"Wavelengths in range 450-550 nm:\", array_boa1)\n",
    "print(\"Wavelengths in range 550-650 nm:\", array_boa2)\n",
    "print(\"Wavelengths in range 650-750 nm:\", array_boa3)\n",
    "print(\"Wavelengths in range 750-850 nm:\", array_boa4)\n",
    "print(\"Wavelengths in range 850-950 nm:\", array_boa5)\n",
    "print(\"Wavelengths in range 950-1050 nm:\", array_boa6)\n",
    "\n",
    "print(\"Wavelengths in range 450-550 nm:\",len(array_boa1))\n",
    "print(\"Wavelengths in range 550-650 nm:\", len(array_boa2))\n",
    "print(\"Wavelengths in range 650-750 nm:\", len(array_boa3))\n",
    "print(\"Wavelengths in range 750-850 nm:\",len (array_boa4))\n",
    "print(\"Wavelengths in range 850-950 nm:\",len (array_boa5))\n",
    "print(\"Wavelengths in range 950-1050 nm:\",len (array_boa6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a750b54b",
   "metadata": {},
   "source": [
    "## Combining bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfaa3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def combined_bands_final(a,b,c,d,e): \n",
    "    combined = np.concatenate((a, b, c,d,e))\n",
    "    element_counts = Counter(combined)    \n",
    "    repeated_bands = {element: count for element, count in element_counts.items() if count > 1}\n",
    "    \n",
    "    # Get unique combined bands that appear more than once\n",
    "    repeated_unique_combined = np.array(list(repeated_bands.keys()))\n",
    "    \n",
    "    # Display counts for bands that appear more than once\n",
    "    for element, count in repeated_bands.items():\n",
    "        print(f\"Band {element}: {count} times\")\n",
    "    \n",
    "    return repeated_unique_combined, repeated_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abca8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_bands, counts=combined_bands_final(final_bands_hba,final_bands_waoa,final_bands_boa,final_bands_hho,final_bands_mpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c1009",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_combined1=[]\n",
    "array_combined2=[]\n",
    "array_combined3=[]\n",
    "array_combined4=[]\n",
    "array_combined5=[]\n",
    "array_combined6=[]\n",
    "\n",
    "for i in range(0,len(optimal_wv_crops)):\n",
    "    if 450<=(list(optimal_wv_crops.values())[i])<550:\n",
    "        array_combined1.append(list(optimal_wv_crops.values())[i])\n",
    "    if 550<=(list(optimal_wv_crops.values())[i])<650:\n",
    "        array_combined2.append(list(optimal_wv_crops.values())[i])\n",
    "    if 650<=(list(optimal_wv_crops.values())[i])<750:\n",
    "        array_combined3.append(list(optimal_wv_crops.values())[i])\n",
    "    if 750<=(list(optimal_wv_crops.values())[i])<850:\n",
    "        array_combined4.append(list(optimal_wv_crops.values())[i])\n",
    "    if 850<=(list(optimal_wv_crops.values())[i])<950:\n",
    "        array_combined5.append(list(optimal_wv_crops.values())[i])\n",
    "    if 950<=(list(optimal_wv_crops.values())[i])<1050:\n",
    "        array_combined6.append(list(optimal_wv_crops.values())[i])\n",
    "        \n",
    "print(\"\\n Combined wavelengths:\\n\")       \n",
    "print(\"Wavelengths in range 450-550 nm:\", array_combined1)\n",
    "print(\"Wavelengths in range 550-650 nm:\", array_combined2)\n",
    "print(\"Wavelengths in range 650-750 nm:\", array_combined3)\n",
    "print(\"Wavelengths in range 750-850 nm:\", array_combined4)\n",
    "print(\"Wavelengths in range 850-950 nm:\", array_combined5)\n",
    "print(\"Wavelengths in range 950-1050 nm:\", array_combined6)\n",
    "\n",
    "print(\"Wavelengths in range 450-550 nm:\",len(array_combined1))\n",
    "print(\"Wavelengths in range 550-650 nm:\", len(array_combined2))\n",
    "print(\"Wavelengths in range 650-750 nm:\", len(array_combined3))\n",
    "print(\"Wavelengths in range 750-850 nm:\",len (array_combined4))\n",
    "print(\"Wavelengths in range 850-950 nm:\",len (array_combined5))\n",
    "print(\"Wavelengths in range 950-1050 nm:\",len (array_combined6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_bands=np.sort(optimal_bands)\n",
    "optimal_wv_crops= {k: selected_values[k] for k in optimal_bands if k in selected_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a269995",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data, final_labels = sample_data(X_s[:, optimal_bands], labels)\n",
    "final_accuracy, final_conf_matrix, final_classification_report, final_model=valuation_fn(final_data,final_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54287b4",
   "metadata": {},
   "source": [
    "## Prediction part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Input the target_image: \\n\")\n",
    "tk.Tk().withdraw()\n",
    "Target_image = filedialog.askopenfilename()\n",
    "print(Target_image)\n",
    "X_op=rasterio.open(Target_image)\n",
    "X_op=X_op.read()\n",
    "X_op=np.moveaxis(X_op,0,-1)\n",
    "X_op_img=X_op.reshape(X_op.shape[0]*X_op.shape[1],X_op.shape[2])\n",
    "X_op_img=(X_op_img-np.min(X_op_img))/(np.max(X_op_img)-np.min(X_op_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac2d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##NDVI masking\n",
    "def ndvi(img):\n",
    "    r=img[:,:,48]#red band in drone image\n",
    "    nir=img[:,:,79]# nir band in drone image\n",
    "    dinom = (nir+r)\n",
    "    numer = (nir-r)\n",
    "    ndvi = np.where(dinom==0.0, 0.0, ((numer/dinom)*1.0))\n",
    "    plt.imshow(ndvi,cmap=\"RdYlGn\", vmin=-1, vmax=1)\n",
    "    plt.colorbar()\n",
    "    return ndvi\n",
    "\n",
    "Xt_ndvi=ndvi(X_op_img.reshape(X_op.shape[0], X_op.shape[1], X_op.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ba6208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lop(ndvi_image):\n",
    "    ndvi_list=[]\n",
    "    non_veg=[]\n",
    "    for i in range(0, len(ndvi_image)) :\n",
    "        if ndvi_image[i]>=0.3:\n",
    "            ndvi_list.append(i) \n",
    "        else:\n",
    "            non_veg.append(i)\n",
    "    return ndvi_list,non_veg\n",
    "            \n",
    "Xt_lop, Xt_image_mask=lop(Xt_ndvi.reshape(X_op.shape[0]*X_op.shape[1]))\n",
    "Xt_ne=X_op_img[Xt_lop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9618788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "def resample_data(resampled_wv,data,data_wv):\n",
    "    resampled_data = np.zeros((len(resampled_wv), data.shape[0])) \n",
    "    print(data.shape[0])\n",
    "    for i in range(data.shape[0]):\n",
    "        interp_func = interp1d(list(data_wv), data[i,:], kind='cubic',fill_value='extrapolate')\n",
    "        resampled_data[:,i] = interp_func(resampled_wv)\n",
    "    return resampled_data.T\n",
    "\n",
    "def resampling_function(image_wv, library_wv,image_data,library_data):\n",
    "    a= max(np.min(image_wv),np.min(library_wv))\n",
    "    b=min(np.max(image_wv),np.max(library_wv))\n",
    "    wv_range=min(len(image_wv),len(library_wv))\n",
    "    sampling_interval=(b-a)/(wv_range-1)\n",
    "    resampled_wv=np.arange(a,b+sampling_interval,sampling_interval)\n",
    "    print(resampled_wv.shape)\n",
    "    tolerance=1e-3\n",
    "    \n",
    "# Function to check if resampled_wv matches any subset of wavelengths (img_wv or lib_wv)\n",
    "    def check_matching_wavelengths(resampled_wv, wavelengths, tolerance):\n",
    "        for i in range(len(wavelengths) - len(resampled_wv) + 1):\n",
    "            sub_wv = wavelengths[i:i + len(resampled_wv)]\n",
    "            if np.isclose(resampled_wv, sub_wv, atol=tolerance).all():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Check if resampled_wv closely matches image_wv\n",
    "    if check_matching_wavelengths(resampled_wv, image_wv, tolerance):\n",
    "        image_data = image_data  # No resampling required\n",
    "        library_data = resample_data(resampled_wv, library_data, library_wv)\n",
    "\n",
    "    # Check if resampled_wv closely matches library_wv\n",
    "    elif check_matching_wavelengths(resampled_wv, library_wv, tolerance):\n",
    "        image_data = resample_data(resampled_wv, image_data, image_wv)\n",
    "        library_data = library_data  # No resampling required\n",
    "\n",
    "    # If no exact match is found, resample both image_data and library_data\n",
    "    else:\n",
    "        image_data = resample_data(resampled_wv, image_data, image_wv)\n",
    "        library_data = resample_data(resampled_wv, library_data, library_wv)\n",
    "        \n",
    "    return resampled_wv, pd.DataFrame(image_data), pd.DataFrame(library_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Resampling image and library data\n",
    "print(\"\\n Input the target_image wavelength file: \\n\")\n",
    "tk.Tk().withdraw()\n",
    "target_wv_file = filedialog.askopenfilename()\n",
    "print(target_wv_file )\n",
    "target_wv=np.loadtxt(target_wv_file)\n",
    "resampled_wv, target_data, source_data=resampling_function(list(msi_wv), list(optimal_wv_crops.values()), Xt_ne, final_data)\n",
    "source_sample_accuracy, source_sample_conf_matrix, source_sample_classification_report, source_sample_model=valuation_fn(source_data,final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52605946",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "def plotting_figure(output_array):\n",
    "    labels_name=['Cabbage', 'Eggplant', 'Tomato']\n",
    "    label_name=['background']+labels_name\n",
    "    colors_image=['black','violet','yellow','crimson','magenta']\n",
    "    filtered_labels_name = [label_name[i] for i in unique_labels]\n",
    "    filtered_colors_image = [colors_image[i] for i in unique_labels]\n",
    "\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(12, 10))\n",
    "    cmap = matplotlib.colors.ListedColormap(filtered_colors_image)\n",
    "    plt.imshow(output_array.reshape(X_op.shape[0], X_op.shape[1]), cmap=cmap)\n",
    "    colors_legend = filtered_colors_image\n",
    "    legend_elements = [\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=filtered_labels_name[i],\n",
    "                   markerfacecolor=colors_legend[i], markersize=10) \n",
    "        for i in range(len(filtered_labels_name))\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.axis('off')\n",
    "    print(\"Select a location to save the figure:\")\n",
    "    save_file_path = filedialog.asksaveasfilename()\n",
    "    print(save_file_path)\n",
    "    plt.savefig(save_file_path, dpi = 600,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ad4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_img=source_sample_model.predict(target_data)\n",
    "y_img_new=np.zeros_like(X_op_img[:,1])\n",
    "y_img_new[Xt_lop] = y_img\n",
    "plotting_figure(y_img_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dce67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
